 1. tokenizer 分词器权重文件下载
 git clone https://www.modelscope.cn/tiansz/bert-base-chinese.git

